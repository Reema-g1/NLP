{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "CYO92EiEOdy8",
        "W6Z9hyXiwLfU"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Personal Information ..\n"
      ],
      "metadata": {
        "id": "IgS2WLwsOG3s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " **NLP**  \\   **Reema Aldanish**.\n"
      ],
      "metadata": {
        "id": "KaOExB4sOP6D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Tokenization and Stop Word Removing"
      ],
      "metadata": {
        "id": "CYO92EiEOdy8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1\tTokenize the provided text by splitting it into individual words. Use the split function in Python, which separates the text based on spaces."
      ],
      "metadata": {
        "id": "KqJeQuQZndN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'AI and NLP are transforming technology. In 2023, AI advancements have accelerated. NLP, a subset of AI, focuses on language. AI technologies, especially NLP, are evolving rapidly. AI and technology are accelerating human improvement. '\n",
        "\n",
        "text1 = text.split()\n",
        "print(text1)"
      ],
      "metadata": {
        "id": "ZkyRBipynh9C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cccbb31-f8e0-4e61-b940-a26de48e7bf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['AI', 'and', 'NLP', 'are', 'transforming', 'technology.', 'In', '2023,', 'AI', 'advancements', 'have', 'accelerated.', 'NLP,', 'a', 'subset', 'of', 'AI,', 'focuses', 'on', 'language.', 'AI', 'technologies,', 'especially', 'NLP,', 'are', 'evolving', 'rapidly.', 'AI', 'and', 'technology', 'are', 'accelerating', 'human', 'improvement.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.2\tCount how many times each token appears. Use collections.Counter"
      ],
      "metadata": {
        "id": "en7mjSl6prdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "tok_counts = Counter(text1)\n",
        "tok_counts"
      ],
      "metadata": {
        "id": "Jgef_Egepu_d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f5bde3e-de20-4b0c-f962-8a44e6add378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'AI': 4,\n",
              "         'and': 2,\n",
              "         'NLP': 1,\n",
              "         'are': 3,\n",
              "         'transforming': 1,\n",
              "         'technology.': 1,\n",
              "         'In': 1,\n",
              "         '2023,': 1,\n",
              "         'advancements': 1,\n",
              "         'have': 1,\n",
              "         'accelerated.': 1,\n",
              "         'NLP,': 2,\n",
              "         'a': 1,\n",
              "         'subset': 1,\n",
              "         'of': 1,\n",
              "         'AI,': 1,\n",
              "         'focuses': 1,\n",
              "         'on': 1,\n",
              "         'language.': 1,\n",
              "         'technologies,': 1,\n",
              "         'especially': 1,\n",
              "         'evolving': 1,\n",
              "         'rapidly.': 1,\n",
              "         'technology': 1,\n",
              "         'accelerating': 1,\n",
              "         'human': 1,\n",
              "         'improvement.': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.3\tExtract and list the unique vocabulary items, also known as distinct tokens or types."
      ],
      "metadata": {
        "id": "FF0OnE9hrNnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_tok = set(text1)\n",
        "\n",
        "unique_tok"
      ],
      "metadata": {
        "id": "04O-Qa9prROX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44f0f4bb-1f83-4eaf-defa-5d9dc81c59d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'2023,',\n",
              " 'AI',\n",
              " 'AI,',\n",
              " 'In',\n",
              " 'NLP',\n",
              " 'NLP,',\n",
              " 'a',\n",
              " 'accelerated.',\n",
              " 'accelerating',\n",
              " 'advancements',\n",
              " 'and',\n",
              " 'are',\n",
              " 'especially',\n",
              " 'evolving',\n",
              " 'focuses',\n",
              " 'have',\n",
              " 'human',\n",
              " 'improvement.',\n",
              " 'language.',\n",
              " 'of',\n",
              " 'on',\n",
              " 'rapidly.',\n",
              " 'subset',\n",
              " 'technologies,',\n",
              " 'technology',\n",
              " 'technology.',\n",
              " 'transforming'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.4\tRemove all punctuation using str.translate(),filter out stop words using nltk.corpus.stopword,  and then print both the list of tokens and the vocabulary set."
      ],
      "metadata": {
        "id": "MUPAP_r4sHTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "stop_words = {\"and\", \"or\", \"but\", \"if\", \"while\", \"with\", \"a\", \"the\", \"in\", \"on\", \"at\", \"to\", \"of\", \"for\", \"by\", \"I\", \"you\", \"it\", \"are\", \"is\"}\n",
        "text = \"AI and NLP are transforming technology. In 2023, AI advancements have accelerated. NLP, a subset of AI, focuses on language. AI technologies, especially NLP, are evolving rapidly. AI and technology are accelerating human improvement.\"\n",
        "translator = str.maketrans('', '', string.punctuation)\n",
        "text_no_punctuation = text.translate(translator)\n",
        "tokens_no_punctuation = text_no_punctuation.split()\n",
        "filtered_tokens = [word for word in tokens_no_punctuation if word.lower() not in stop_words]\n",
        "vocabulary = set(filtered_tokens)\n",
        "\n",
        "print(\"Tokens:\", filtered_tokens)\n",
        "print(\"Vocabulary:\", vocabulary)"
      ],
      "metadata": {
        "id": "RkfUNxAJvzpl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80cabba2-215b-4e8a-a322-c0e1efe48aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['AI', 'NLP', 'transforming', 'technology', '2023', 'AI', 'advancements', 'have', 'accelerated', 'NLP', 'subset', 'AI', 'focuses', 'language', 'AI', 'technologies', 'especially', 'NLP', 'evolving', 'rapidly', 'AI', 'technology', 'accelerating', 'human', 'improvement']\n",
            "Vocabulary: {'accelerating', 'improvement', 'rapidly', 'have', '2023', 'advancements', 'subset', 'focuses', 'technologies', 'accelerated', 'language', 'especially', 'transforming', 'human', 'evolving', 'AI', 'NLP', 'technology'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: One Complete Code"
      ],
      "metadata": {
        "id": "W6Z9hyXiwLfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk import pos_tag\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "text = \"\"\"\n",
        "Contact John Doe at john11.d_oe@example.com for more details. Our team achieved a\n",
        "25% increase in efficiency in 11-07-2023 and 3-2-2023. Visit our website at\n",
        "http://www.example_23.com or https://www.Energy123.org. For inquiries, call 5551234.\n",
        "Join us on 23223 street for the annual conference.\n",
        "\"\"\"\n",
        "text = re.sub(r'\\b\\d{1,2}-\\d{1,2}-\\d{4}\\b', ' DATE ', text)\n",
        "text = re.sub(r'\\b\\d+\\b', ' NUM ', text)\n",
        "text = re.sub(r'\\b[\\w.-]+@[\\w.-]+.\\w+\\b', ' Email ', text)\n",
        "text = re.sub(r'https?://\\S+|www\\.\\S+', ' LINK ', text)\n",
        "text = re.sub(r'[^\\w\\s]', '', text)\n",
        "tokens = word_tokenize(text)\n",
        "print(\"Tokens after regular expression replacement:\", tokens)\n",
        "stop_words_set = set(stopwords.words('english'))\n",
        "filtered_tokens = [token for token in tokens if token.lower() not in stop_words_set]\n",
        "print(\"Tokens after removing stop words:\", filtered_tokens)\n",
        "stemmer = PorterStemmer()\n",
        "stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]\n",
        "print(\"Tokens after stemming:\", stemmed_tokens)\n",
        "tagged_tokens = pos_tag(stemmed_tokens)\n",
        "print(\"Tagged tokens:\", tagged_tokens)\n"
      ],
      "metadata": {
        "id": "9-RP8WwSzQiT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e893101-a9e8-4ae7-a6a6-3650552887d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens after regular expression replacement: ['Contact', 'John', 'Doe', 'at', 'Email', 'more', 'details', 'Our', 'team', 'achieved', 'a', 'NUM', 'increase', 'in', 'efficiency', 'in', 'DATE', 'and', 'DATE', 'Visit', 'our', 'website', 'at', 'LINK', 'or', 'LINK', 'For', 'inquiries', 'call', 'NUM', 'Join', 'us', 'on', 'NUM', 'street', 'for', 'the', 'annual', 'conference']\n",
            "Tokens after removing stop words: ['Contact', 'John', 'Doe', 'Email', 'details', 'team', 'achieved', 'NUM', 'increase', 'efficiency', 'DATE', 'DATE', 'Visit', 'website', 'LINK', 'LINK', 'inquiries', 'call', 'NUM', 'Join', 'us', 'NUM', 'street', 'annual', 'conference']\n",
            "Tokens after stemming: ['contact', 'john', 'doe', 'email', 'detail', 'team', 'achiev', 'num', 'increas', 'effici', 'date', 'date', 'visit', 'websit', 'link', 'link', 'inquiri', 'call', 'num', 'join', 'us', 'num', 'street', 'annual', 'confer']\n",
            "Tagged tokens: [('contact', 'NN'), ('john', 'NN'), ('doe', 'NN'), ('email', 'NN'), ('detail', 'NN'), ('team', 'NN'), ('achiev', 'NN'), ('num', 'NN'), ('increas', 'NNS'), ('effici', 'VBP'), ('date', 'NN'), ('date', 'NN'), ('visit', 'NN'), ('websit', 'NN'), ('link', 'NN'), ('link', 'VBP'), ('inquiri', 'NN'), ('call', 'NN'), ('num', 'NN'), ('join', 'NN'), ('us', 'PRP'), ('num', 'JJ'), ('street', 'NN'), ('annual', 'JJ'), ('confer', 'NN')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    }
  ]
}